---
---

@inproceedings{rungta-etal-2022,
    title = "Geographic Citation Gaps in NLP Research",
    author = "Rungta*, Mukund and Singh*, Janvijay and Mohammad, Saif M. and Yang, Diyi",
    booktitle = "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2022",
    address = "Abu Dhabi",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/2210.14424",
    doi = "10.48550/ARXIV.2210.14424",
    preview={geographic-citation-gaps.jpg},
    abstract="In a fair world, people have equitable opportunities to education, to conduct scientiÔ¨Åc research, to publish, and to get credit for their work, regardless of where they live. However, it is common knowledge among researchers that a vast number of papers accepted at top NLP venues come from a handful of western countries and (lately) China; whereas, very few papers from Africa and South America get published. Similar disparities are also believed to exist for paper citation counts. In the spirit of ‚Äú what we do not measure, we cannot improve ‚Äù, this work asks a series of questions on the relationship between geographical location and publication success (acceptance in top NLP venues and citation impact). We Ô¨Årst created a dataset of 70,000 papers from the ACL Anthology, extracted their meta-information, and generated their citation network. We then show that not only are there substantial geographical disparities in paper acceptance and citation but also that these disparities persist even when controlling for a number of vari-ables such as venue of publication and sub-Ô¨Åeld of NLP. Further, despite some steps taken by the NLP community to improve geographical diversity, we show that the disparity in publication metrics across locations is still on an increasing trend since the early 2000s. We release our code and dataset here: https:// github.com/iamjanvijay/acl-cite-net .",
    code="https://github.com/iamjanvijay/acl-cite-net",
    pdf="https://arxiv.org/pdf/2210.14424.pdf"
}

@inproceedings{singh-etal,
  doi = {10.48550/ARXIV.2210.06444},
  url = {https://arxiv.org/abs/2210.06444},
  author = {Singh, Janvijay and Bai, Fan and Wang, Zhen},
  title = {Entity Tracking via Effective Use of Multi-Task Learning Model and Mention-guided Decoding},
  publisher = {arXiv},
  booktitle = "Under Review in the Conference of the European Chapter of the Association for Computational Linguistics (EACL)",
  year = "2023",
  preview={ent-tracking.jpg},
  code="https://github.com/iamjanvijay/SET",
  arxiv="2210.06444"
}

@inproceedings{singh-2020-publishincovid19,
    title = "Sentence and List Extraction in Noisy {PDF} Text Using a Hybrid Deep Learning and Rule-Based Approach",
    author = "Singh, Janvijay",
    booktitle = "In Proceedings of the Second Workshop on Financial Technology and Natural Language Processing @ IJCAI",
    year = "2020",
    address = "Kyoto, Japan",
    publisher = "-",
    url = "https://aclanthology.org/2020.finnlp-1.9",
    pages = "55--61",
    preview={fin-sbd.jpg},
    abstract = "This paper describes the approach that we employed to tackle the FinSBD-2 shared task in IJCAI-2020. FinSBD-2 comprises of two subtasks: 1) extraction of boundaries of sentences, lists and items from noisy PDF (financial documents) text and 2) organisation of lists and items in a visual hierarchy. We solve these subtasks in two phases. In the first phase, we pre-process the data to embed relevant visual cues and form nonrecursive and non-hierarchical tags. We then formulate the boundary prediction problem as a sequence labelling task and evaluate two neural architectures, namely BiLSTM-CRF and BERT. In the second phase, we identify the recursive relation among different items as well as their hierarchical visual layout. A rule-based method is used to achieve desired recursiveness and hierarchy in tags predicted from the first phase. The rules are based on visual cues like left-indentation and bullet-style of items. Our combined final approach achieved an F1-score of 0.937 on subtask-1 and 0.844 on subtask-2 for the English test set. We were ranked first overall in terms of MEAN F1-score.",
    pdf="https://aclanthology.org/2020.finnlp-1.9.pdf",
    special = "ü•á Shared Task Winner"
}

@inproceedings{singh-wadhawan-2020-publishincovid19,
    title = "Entity Recognition in Wet Lab Protocols using Structured Learning Ensemble and Contextualised Embeddings",
    author = "Singh, Janvijay  and
      Wadhawan, Anshul",
    booktitle = "In Proceedings of the Sixth Workshop on Noisy User-generated Text @ EMNLP",
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.wnut-1.35",
    doi = "10.18653/v1/2020.wnut-1.35",
    pages = "273--280",
    preview={wet-lab.jpg},
    abstract = "In this paper, we describe the approach that we employed to address the task of Entity Recognition over Wet Lab Protocols - a shared task in EMNLP WNUT-2020 Workshop. Our approach is composed of two phases. In the first phase, we experiment with various contextualised word embeddings (like Flair, BERT-based) and a BiLSTM-CRF model to arrive at the best-performing architecture. In the second phase, we create an ensemble composed of eleven BiLSTM-CRF models. The individual models are trained on random train-validation splits of the complete dataset. Here, we also experiment with different output merging schemes, including Majority Voting and Structured Learning Ensembling (SLE). Our final submission achieved a micro F1-score of 0.8175 and 0.7757 for the partial and exact match of the entity spans, respectively. We were ranked first and second, in terms of partial and exact match, respectively.",
    pdf="https://aclanthology.org/2020.wnut-1.35.pdf",
    special = "ü•á Shared Task Winner"
}

@INPROCEEDINGS{8906597,
  author={Singh, Janvijay and Joshi, Raviraj},
  booktitle={In Proceedings of the International Conference on Speech Technology and Human-Computer Dialogue (SpeD)}, 
  title={Background Sound Classification in Speech Audio Segments}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/SPED.2019.8906597},
  preview={sound-classification.jpg},
  abstract="Background sound classification is the task of identifying secondary sound sources in the surrounding environment. Real-time speech is always accompanied by a context. This context can be very helpful in enhancing the behavior of a variety of applications. Traditionally, audio classification tasks have mainly focused on speech due to its wide applicability. Recent works have explored environmental scene classification using acoustic features. Availability of different datasets like UrbanSound, ESC50, and AUDIOSET have further aided the process. Previous works have mostly focused on the classification of independently occurring acoustic events. In this work, we explore the classification of background sound in audio recordings containing human speech. We prepare a new dataset YBSS-200 using youtube videos where each sample contains a distinct background sound and an accompanying foreground human voice. We present a convolutional neural network based transfer learning approach using a VGG like Network for classification of context in such acoustic signals. Specific data augmentation techniques were used to improve the classification results.",
  pdf="https://www.researchgate.net/profile/Raviraj-Joshi/publication/337526768_Background_Sound_Classification_in_Speech_Audio_Segments/links/5de133e34585159aa453d844/Background-Sound-Classification-in-Speech-Audio-Segments.pdf",
  html="https://ieeexplore.ieee.org/document/8906597"
  }
